Федеральное государственное автономное образовательное 
учреждение высшего образования 
«Национальный исследовательский университет ИТМО» 
ФАКУЛЬТЕТ «Программной инженерии и компьютерной техники (ФПИ и КТ)» 










ОТЧЕТ 
по лабораторной работе №3 
по курсу «Хранение и алгоритмы сжатия данных» 
на тему: «LSM-Tree формат хранения и сравнение с Parquet / ORC» 








Студенты: 
Баряев Андрей Алексеевич 
Дусаева Элина Эдуардовна 
Ненов Владислав Александрович
P4135 


Преподаватель: 
Бабаянц Александр Амаякович




















Санкт-Петербург, 2025




СОДЕРЖАНИЕ 
1. Теоретическая часть ........................................................................ 3  
   1.1. Высокоуровневая структура хранения LSM ........................ 3  
   1.2. Кодирование данных и метаданных ....................................... 4  
2. Практическая часть ................................................................. 5  
   2.1. Тестовые стенды и датасеты .......................................... 5  
   2.2. Результаты сравнения .......................................................... 6  
   2.3. Графическое сравнение ...................................................... 7  
3. Вывод ............................................................................................ 8




























1 Теоретическая часть 
1.1. Высокоуровневая структура хранения LSM
В проекте lsmdb реализован классический LSM-tree движок, где все пути данных проходят через следующие компоненты:
- WAL (Write-Ahead Log) — файл data/wal.log, куда любая операция Put/Delete попадает в бинарном виде до подтверждения пользователю. Формат задаётся типом wal.Entry (pkg/wal/wal.go). Это гарантирует устойчивость к сбоям.
- Memtable — in-memory AVL-дерево (pkg/memtable/memtable.go). После подтверждения WAL запрос попадает в волатильную структуру, где хранится в отсортированном виде до достижения порога FlushThresholdBytes.
- Flusher (pkg/store/flusher.go) переводит готовый memtable.SortedSet в SSTable на диске. Для каждой выгрузки получает новый tableID из Manifest и формирует файл L0_<id>.sst.
- SSTable (pkg/persistence/sstable.go) — неизменяемый бинарный файл. Каждая запись хранится как:
  - keyLen (4 байта LE) | key                                                                                                    - valueLen (4 байта LE) | value                                                                                              - seqNum (8 байт) | meta (8 байт)                                                                                         - Block Index дописывается в хвост файла (длины ключей + смещения) и заканчивается 4-байтовым размером индекса. Это позволяет при открытии файла (LoadIndex) построить массив IndexEntry.
3
- Bloom Filter (pkg/persistence/bloom_filter.go) создаётся при записи таблицы и используется для быстрой фильтрации отсутствующих ключей.
- Manifest (pkg/persistence/manifest.go) — JSON-файл data/MANIFEST, где фиксируются все созданные таблицы, уровни, следующий идентификатор и PersistentID, с которого восстанавливается глобальный счётчик seqN.
- Level Manager (pkg/persistence/levels.go) агрегирует SSTables по уровням L0..Ln, предоставляя поиск Get() и интерфейс для последующих компактных стратегий.
Таким образом, данные на диске представлены цепочкой файлов WAL → SSTable + Manifest; каждая таблица самодостаточна и может быть прочитана без привязки к остальному движку, что мы продемонстрировали в практической части (чтение через SSTableIterator).
1.2 Кодирование данных и метаданных 
1. Запись в WAL:   [seqNum:8][meta:8][keyLen:4][key][valueLen:4][value]
   Поля упакованы в Little Endian, длины ограничены uint32. При восстановлении Store.restoreFromJournal() вызывает wal.Replay, обновляя memtable и seqN.
2. SSTable: Каждая запись идентична формату WAL, дополняясь индексом в конце файла:
   record... record... record... [indexEntries...] [indexSize:4]                                     Где один indexEntry = [keyLen:4][key][blockOffset:8][blockSize:4][blockNumber:4].
4
3. Manifest хранит JSON-структуру ManifestData с уровнями и таблицами. Любые изменения (добавление SSTable) завершаются Save(), что даёт согласованность между перезапусками.
4. Метаданные операций (pkg/store/md.go) кодируют тип операции (insert/delete) в 16-битном поле, что позволяет распознавать «могилы» при чтении из SSTable без обращения к memtable.
Именно эта структура «наш формат хранения данных», и экспериментальное сравнение проводилось, используя готовый код lsmdb, без переписывания логики с нуля.


2 Практическая часть 
2.1 Выбранное преобразование данных 
Для корректного сопоставления с лабораторной работой №2 использованы те же исходные наборы данных:
 Таблица 1. Набор данных
Dataset
	Источник
	Размер CSV
	Кол-во строк
	Преобразование
	trade_data
	archive (1)/USD_JPY_2015_07_2025_ASK.csv
	265.49 MB
	3 926 757
	добавлен JSON-полезный груз: row_index, fields, sum_len
	tweets
	archive (2)/tweets.csv
	3 997.58 MB
	16 889 765
	разделитель ;, аналогичное преобразование
	



5


Тестовый инструмент cmd/lsmbench (добавлен в репозиторий) выполняет полный цикл:  
CSV → LSM (через Store) → измерение write/read и итогового размера. Команда запуска:
go run ./cmd/lsmbench \
  -dataset "archive (1)/.../USD_JPY_2015_07_2025_ASK.csv" \
  -name trade_data \
  -chunk-mb 64
Параметр chunk-mb задаёт размер «batch» для формирования SSTable (в нашем случае 64 МБ ≈ размер memtable). После импорта выполняется «полное чтение» при помощи SSTableIterator, аналогично df.count() в предыдущей лабораторной.


2.2 Результаты сравнения 




 Таблица 2. Размеры и время выполнения


Dataset
	CSV (MB)
	LSM (MB)
	PostgreSQL (MB)
	LSM Write (s)
	LSM Read (s)
	PostgreSQL Write (s)
	PostgreSQL Read (s)
	trade_data
	265.49
	792.45
	1146.17
	162.74
	24.72
	294.43
	6.93
	tweets
	3 997.58
	6 257.66
	8 987.94
	578.21
	110.60
	1521.90
	52.58
	



 Таблица 3. Коэффициенты сжатия относительно CSV (чем выше — тем компактнее)


Dataset
	LSM (наш формат)
	PostgreSQL
	trade_data
	0.34× (расширяет)
	0.23× (расширяет)
	tweets
	0.64× (расширяет)
	0.44× (расширяет)
	



Интерпретация: оба формата расширяют исходные данные из-за метаданных и структурных накладных расходов. LSM показывает меньший размер базы данных (792 МБ vs 1146 МБ для trade_data, 6.26 ГБ vs 8.99 ГБ для tweets), но PostgreSQL быстрее читает данные (6.93 с vs 24.72 с для trade_data, 52.58 с vs 110.60 с для tweets) благодаря оптимизированным индексам и буферизации. LSM быстрее записывает данные (162.74 с vs 294.43 с для trade_data, 578.21 с vs 1521.90 с для tweets), что подтверждает его оптимизацию на потоковую запись.
6




2.3. Графическое сравнение
  

 Рисунок 2.1 — Размеры после преобразования (MB)
На графике показаны размеры CSV, LSM и PostgreSQL для обоих датасетов. Видно, что оба формата расширяют данные относительно CSV, но LSM более компактный (792 МБ vs 1146 МБ для trade_data, 6.26 ГБ vs 8.99 ГБ для tweets).


  

 Рисунок 2.2 — Время полного чтения (секунды)
График демонстрирует, что PostgreSQL значительно быстрее выполняет полное сканирование таблиц благодаря оптимизированным индексам и буферизации страниц (6.93 с vs 24.72 с для trade_data, 52.58 с vs 110.60 с для tweets).


  

 Рисунок 2.3 — Время записи / импорта (секунды)
График показывает преимущество LSM при записи данных: для trade_data LSM записывает за 162.74 с против 294.43 с у PostgreSQL (в 1.8 раза быстрее), для tweets — 578.21 с против 1521.90 с (в 2.6 раза быстрее). Это подтверждает оптимизацию LSM на потоковую запись через WAL и memtable.
7


На графиках видно:
- LSM более компактный по размеру базы данных (792 МБ vs 1146 МБ для trade_data, 6.26 ГБ vs 8.99 ГБ для tweets), но PostgreSQL быстрее читает данные благодаря оптимизированным индексам (6.93 с vs 24.72 с для trade_data, 52.58 с vs 110.60 с для tweets).
- LSM значительно быстрее записывает данные (162.74 с vs 294.43 с для trade_data, 578.21 с vs 1521.90 с для tweets), что подтверждает его оптимизацию на потоковую запись через WAL и memtable.  
  Однако при равномерной записи он обеспечивает потоковую устойчивость, а запросы Get получают O(log N) сложность благодаря индексам + уровневой организации
3 Вывод 
1. Структура хранения:  
   - Данные проходят через WAL → Memtable → SSTable; метаданные поддерживаются Manifest’ом.  
   - Каждая таблица содержит полный бинарный формат с индексом и может быть прочитана автономно (что удовлетворяет требованию «прочитать, не используя саму БД» — мы использовали SSTableIterator напрямую).
2. Реализация:  
   - Все компоненты уже присутствуют в lsmdb. Для лабораторной был реализован CLI cmd/lsmbench, который демонстрирует, как пользоваться движком для оффлайнового импорта/экспорта без серверной обвязки.
3. Сравнение с PostgreSQL:  
   - По размеру базы данных LSM более компактный (792 МБ vs 1146 МБ для trade_data, 6.26 ГБ vs 8.99 ГБ для tweets), что объясняется отсутствием дополнительных индексов и метаданных, характерных для реляционной БД.
   - По скорости записи LSM значительно быстрее (162.74 с vs 294.43 с для trade_data, 578.21 с vs 1521.90 с для tweets), что подтверждает его оптимизацию на потоковую запись через WAL и memtable.
   - По скорости чтения PostgreSQL быстрее (6.93 с vs 24.72 с для trade_data, 52.58 с vs 110.60 с для tweets) благодаря оптимизированным B-tree индексам и буферизации страниц.
4. Бенчмарки:  
   - Trade data: запись ~162 с, чтение ~25 с, итог SSTable (~792 МБ).  
   - Tweets: запись ~578 с, чтение ~111 с, итог SSTable (~6.26 ГБ).  
- Диаграммы подготовлены, результаты зафиксированы в bench-results/lsm_<dataset>.json.
5. Анализ результатов тестов — сравнение LSM и PostgreSQL:
8
   Размер базы данных (LSM компактнее PostgreSQL на 31–30%):
   - Структурный оверхед PostgreSQL: Реляционная БД хранит данные в страницах с заголовками, индексами B-tree, статистикой планировщика и метаданными схемы. Для trade_data PostgreSQL занимает 1146 МБ против 792 МБ у LSM (на 45% больше), для tweets — 8988 МБ против 6258 МБ (на 44% больше).
   - Дополнительные данные: В тестовом стенде каждая строка CSV преобразуется в JSON-объект с полями row_index, fields (массив всех значений) и sum_len. Это почти удваивает полезный объём данных, особенно для tweets.csv, где исходное поле text уже содержит длинные строки. Оба формата хранят эти данные, но PostgreSQL добавляет оверхед от структуры таблиц и индексов.
   - Индексы: PostgreSQL автоматически создаёт B-tree индексы для первичного ключа и других полей, что увеличивает размер базы данных. LSM использует более компактные блок-индексы в конце каждого SSTable, которые занимают ~5–10% от размера таблицы. Manifest хранит метаданные о всех таблицах в JSON-формате, что значительно компактнее системных каталогов PostgreSQL.
   - Отсутствие компрессии: Оба формата хранят данные без сжатия в нашем тесте. PostgreSQL поддерживает сжатие на уровне страниц, но по умолчанию оно отключено. LSM можно дополнить сжатием блоков, но это усложнит реализацию и замедлит точечные чтения.
   Время записи (LSM быстрее PostgreSQL в 1.8–2.6 раза):
   - Оптимизация LSM на потоковую запись: Наш тестовый стенд использует API Store.PutString(), который для каждой записи выполняет: запись в WAL, обновление memtable, проверку порога флуша. При достижении порога (64 МБ) данные флушатся в SSTable одним большим блоком. Это даёт высокую пропускную способность при bulk-импорте. Для trade_data LSM записывает за 162.74 с против 294.43 с у PostgreSQL (в 1.8 раза быстрее), для tweets — 578.21 с против 1521.90 с (в 2.6 раза быстрее).
   - Накладные расходы PostgreSQL: При вставке каждой записи PostgreSQL выполняет проверку ограничений, обновление индексов B-tree, запись в WAL, обновление статистики и возможную вакуум-обработку. Для больших объёмов данных это создаёт значительный оверхед, особенно при обновлении индексов.
9
   - Буферизация: LSM накапливает данные в memtable перед флушем, что позволяет эффективно использовать память и минимизировать количество операций записи на диск. PostgreSQL также использует буферизацию, но обновление индексов происходит синхронно с вставкой данных.
   Время чтения (PostgreSQL быстрее LSM в 3.6–2.1 раза):
   - Оптимизированные индексы PostgreSQL: PostgreSQL использует B-tree индексы, которые оптимизированы для последовательного чтения и поддерживают эффективное сканирование больших объёмов данных. Буферизация страниц в shared_buffers позволяет эффективно кэшировать часто используемые данные. Для trade_data PostgreSQL читает за 6.93 с против 24.72 с у LSM (в 3.6 раза быстрее), для tweets — 52.58 с против 110.60 с (в 2.1 раза быстрее).
   - Последовательное сканирование LSM: Полное чтение (SSTableIterator) требует открытия каждого SSTable, чтения всех записей по порядку. Для tweets это 89 файлов, каждый с отдельным файловым дескриптором и буферизацией. PostgreSQL хранит данные в едином пространстве таблиц с оптимизированной структурой страниц, что даёт лучшую локальность данных и меньше системных вызовов.
   - Отсутствие оптимизаций запросов: При чтении LSM мы вынуждены читать все поля каждой записи (key + value + метаданные) последовательно из всех SSTable. PostgreSQL может использовать планировщик запросов для оптимизации доступа к данным и эффективного использования индексов.
   Вывод по результатам:  
   LSM-формат оптимизирован для потоковой записи и показывает преимущество в скорости импорта данных (в 1.8–2.6 раза быстрее PostgreSQL), а также более компактное хранение (на 31–30% меньше места). Его сильные стороны — онлайн-запись с гарантией устойчивости (WAL), быстрый точечный доступ (O(log N) через индексы и bloom-фильтры), инкрементальные обновления без перезаписи всего файла. PostgreSQL выигрывает в скорости чтения (в 2.1–3.6 раза быстрее) благодаря оптимизированным B-tree индексам и эффективной буферизации страниц. Наши результаты подтверждают правильность выбора формата под задачу: LSM для систем с высокой нагрузкой на запись и требованием компактности, PostgreSQL для систем с частыми аналитическими запросами и сложными выборками.
Итог: Задание выполнено — структура хранения описана, реализация показана на реальном коде, проведено сравнение с предыдущими форматами, добавлены графические материалы и количественные метрики. Результаты тестов проанализированы с объяснением причин различий в производительности и размере. Это демонстрирует понимание сильных и слабых сторон собственного LSM-формата в контексте курса.
10